{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('d:\\\\FRAX_project\\\\FraxBot\\\\src\\\\')\n",
    "\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "# from apscheduler.schedulers.background import BackgroundScheduler, BlockingScheduler\n",
    "import yaml\n",
    "import schedule\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from common import mongodb_connect\n",
    "\n",
    "\n",
    "def datetime_from_timestamp(timestamp):\n",
    "    try:\n",
    "        timestamp = int(timestamp)\n",
    "        dt_object = datetime.fromtimestamp(timestamp)\n",
    "        return str(dt_object)\n",
    "    except ValueError:\n",
    "        print(\"Invalid timestamp. Please provide a valid Unix timestamp (seconds since January 1, 1970).\")\n",
    "        return None\n",
    "\n",
    "def query_subgraph(query: str):\n",
    "    print(\"Querying Subgraph...\")\n",
    "    \"\"\"\"Query the subgraph with apost request\"\"\"\n",
    "    request = requests.post('https://api.thegraph.com/subgraphs/name/frax-finance-data/fraxlend-subgraph---mainnet',\n",
    "                            '',\n",
    "                            json={'query': query})\n",
    "    if request.status_code == 200:\n",
    "        return request.json()\n",
    "    else:\n",
    "        raise Exception(f\"Query failed. HTTP return code is - {request.status_code}\")\n",
    "    \n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self):\n",
    "        self.round_decimals = 2\n",
    "        self.query_pairs_dailyhistory = \"\"\"\n",
    "            {\n",
    "            pairs {\n",
    "                address\n",
    "                name\n",
    "                symbol\n",
    "                maxLTV\n",
    "                \n",
    "                asset{\n",
    "                name\n",
    "                symbol\n",
    "                decimals\n",
    "                }\n",
    "                collateral {\n",
    "                id\n",
    "                name\n",
    "                symbol\n",
    "                decimals\n",
    "                }\n",
    "                dailyHistory(first: 1, orderBy: timestamp, orderDirection: desc) {\n",
    "                id\n",
    "                exchangeRate\n",
    "                totalAssetAmount\n",
    "                totalAssetShare\n",
    "                totalCollateral\n",
    "                totalBorrowAmount\n",
    "                totalBorrowShare\n",
    "                interestPerSecond\n",
    "                \n",
    "                timestamp\n",
    "                }\n",
    "            }\n",
    "            }\n",
    "            \"\"\"\n",
    "        self.query_users_positions = \"\"\"{{\n",
    "            users({0}) {{\n",
    "            id\n",
    "            positions{{\n",
    "                pair{{\n",
    "                id\n",
    "                }}\n",
    "                borrowedAssetShare\n",
    "                lentAssetShare\n",
    "                depositedCollateralAmount\n",
    "                timestamp\n",
    "            }}\n",
    "            }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        # Run steps\n",
    "        # connect MDB collectioons\n",
    "        (db, pairs, user_positions, user_notifications, telegram_metadata, subscription) = mongodb_connect()\n",
    "        \n",
    "        print(\"[Step-1]: getting and ingesting daily history...\\n\")\n",
    "        pdf_pairs_dailyhistory, data_pairs_dailyhistory = self.get_pairs_dailyhistory(pairs)\n",
    "        print(\"[Step-2]: getting and ingesting user positions...\\n\")\n",
    "        data_users_positions = self.get_user_positions(user_positions)\n",
    "        print(\"[Step-3]: Creating and ingesting user notifications...\\n\")\n",
    "        data_notifications = self.create_notification_data(data_users_positions, pdf_pairs_dailyhistory, user_notifications)\n",
    "    \n",
    "    def simplify_dailyHistory(self, data_list_dict: list[dict], key: str):\n",
    "        \"\"\"\n",
    "        Converts the daily History key to a dict() from a list(dict())\n",
    "        \"\"\"\n",
    "        print(\"De-listing daily history value...\")\n",
    "        for data_dict in data_list_dict:\n",
    "            # Extract the single dictionary from the list (if present)\n",
    "            if isinstance(data_dict.get(key), list) and len(data_dict[key]) == 1:\n",
    "                data_dict[key] = data_dict[key][0]\n",
    "            else:\n",
    "                raise AttributeError(f\"Pairs data data {key} format is wrong\")\n",
    "\n",
    "        return data_list_dict\n",
    "    \n",
    "    def filter_zero_positions(self, pos: dict) ->bool:\n",
    "        if abs(int(pos['borrowedAssetShare'])) +  abs(int(pos['lentAssetShare']))+ abs(int(pos['depositedCollateralAmount'])) ==0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    def get_pairs_dailyhistory(self, pairs_collections):\n",
    "        \"\"\"Query the pairs daily histrory and update the data into database and created pandas DF for fater IR\"\"\"\n",
    "        print(\"Staring getting pairs data...\")\n",
    "        try:\n",
    "            results_pairs_dailyhistory = query_subgraph(self.query_pairs_dailyhistory)\n",
    "        except Exception as error:\n",
    "            # handle the exception\n",
    "            print(\"An exception occurred:\", type(error).__name__)\n",
    "        if results_pairs_dailyhistory['data']:\n",
    "            if results_pairs_dailyhistory['data']['pairs']:\n",
    "                data_pairs_dailyhistory = results_pairs_dailyhistory['data']['pairs']\n",
    "                # returns a list of dictoinary\n",
    "                # de-list daily history\n",
    "                data_pairs_dailyhistory = self.simplify_dailyHistory(data_pairs_dailyhistory, \"dailyHistory\")\n",
    "                print(\"Iterating over pairs...\")\n",
    "                for pair_info_dict in data_pairs_dailyhistory:\n",
    "                    \n",
    "                    # Extract decimals\n",
    "                    pair_asset_decimal = int(pair_info_dict[\"asset\"][\"decimals\"])\n",
    "                    pair_col_decimal = int(pair_info_dict[\"collateral\"][\"decimals\"])\n",
    "                    assert (pair_asset_decimal!= 0 and pair_col_decimal !=0), \"Decimals cant be zero\"\n",
    "\n",
    "                    # extract total bprrow/ lend amounts\n",
    "                    total_borrow_amt_raw = int(pair_info_dict[\"dailyHistory\"][\"totalBorrowAmount\"])\n",
    "                    total_col_amt_raw = int(pair_info_dict[\"dailyHistory\"][\"totalCollateral\"])\n",
    "                    total_asset_amt_raw = int(pair_info_dict[\"dailyHistory\"][\"totalAssetAmount\"])\n",
    "                    # calcualte features\n",
    "                    total_borrow_amt_scaled = round(total_borrow_amt_raw/ 10**pair_asset_decimal, self.round_decimals)\n",
    "                    total_col_amt_scaled= round(total_col_amt_raw/ 10**pair_col_decimal, self.round_decimals)\n",
    "                    total_asset_amt_scaled = round(total_asset_amt_raw/ 10**pair_asset_decimal, self.round_decimals)\n",
    "\n",
    "                    pair_info_dict[\"show_pair_symbol\"] = f\"{pair_info_dict['collateral']['symbol']}/{pair_info_dict['asset']['symbol']}\"\n",
    "                    \n",
    "                    # calculate exchange rate \n",
    "                    # exchange rate  = 1 /(exchangeRate/ collateral_decimals) # UNIT FRAX\n",
    "                    ex_rate_init = int(pair_info_dict[\"dailyHistory\"][\"exchangeRate\"])/ 10**pair_col_decimal\n",
    "                    if ex_rate_init == 0:\n",
    "                        ex_rate_scaled = None\n",
    "                    else:\n",
    "                        ex_rate_scaled = round(1/ex_rate_init, self.round_decimals)\n",
    "                    # calcualte Borrow APR  & Lend APR \n",
    "                    interest_per_year = round((int(pair_info_dict[\"dailyHistory\"][\"interestPerSecond\"])/ 10**pair_asset_decimal) * 60 * 60 * 24 * 365,\n",
    "                                            self.round_decimals)\n",
    "                    # borrow_APR = (interestPerSecond / 10**pair_asset_decimal) * * 60 * 60 * 24 * 365 #UNIt - %\n",
    "                    borrow_APR = interest_per_year *100\n",
    "                    # lend_APR = (borrow_APR / totalAssetAmount) * totalBorrowAmount #UNIt - %\n",
    "                    if total_asset_amt_scaled ==0:\n",
    "                        lend_APR = None\n",
    "                    else:\n",
    "                        lend_APR = round((borrow_APR / total_asset_amt_scaled) * total_borrow_amt_scaled, self.round_decimals)\n",
    "                    # borrow_APR > lend_APR\n",
    "                    # Add features to the dictionary\n",
    "                    pair_info_dict[\"dailyHistory\"][\"total_borrow_amt_scaled\"] = total_borrow_amt_scaled\n",
    "                    pair_info_dict[\"dailyHistory\"][\"total_col_amt_scaled\"] = total_col_amt_scaled\n",
    "                    pair_info_dict[\"dailyHistory\"][\"total_asset_amt_scaled\"] = total_asset_amt_scaled\n",
    "                    pair_info_dict[\"dailyHistory\"][\"ex_rate_scaled\"] = ex_rate_scaled\n",
    "                    pair_info_dict[\"dailyHistory\"][\"borrow_APR\"] = borrow_APR\n",
    "                    pair_info_dict[\"dailyHistory\"][\"lend_APR\"] = lend_APR\n",
    "\n",
    "                    time = int(pair_info_dict[\"dailyHistory\"][\"timestamp\"])\n",
    "                    pair_info_dict[\"dailyHistory\"][\"date_time\"] = datetime_from_timestamp(time) \n",
    "                # convert to pandas dataframe for faster IR\n",
    "                print(\"Creatinig pandas dataframe...\")\n",
    "                pdf_pairs_dailyhistory = pd.json_normalize(data_pairs_dailyhistory, sep='_')\n",
    "                print(\"Running MongoDB operations on pairs_collections...\")\n",
    "                pairs_collections.drop()\n",
    "                pairs_collections.insert_many(data_pairs_dailyhistory)\n",
    "                \n",
    "        return pdf_pairs_dailyhistory, data_pairs_dailyhistory\n",
    "    \n",
    "    def get_user_positions(self, user_positions_collection) -> list[dict]: \n",
    "        \"\"\"Query the grapgh data and get the user positions as list of dictionaries\"\"\"\n",
    "        query_user_chunk_num =1000\n",
    "        # initially start with the first 200 users\n",
    "        results_users_positions = query_subgraph(self.query_users_positions.format(f\"first: {query_user_chunk_num}\"))\n",
    "        if results_users_positions['data']:\n",
    "            if results_users_positions['data']['users']:\n",
    "                data_users_positions = results_users_positions['data']['users']\n",
    "        print(\"initial length of data_users_positions -\", len(data_users_positions))\n",
    "        # then itererate over 200 users and skip\n",
    "\n",
    "        skip_users = query_user_chunk_num\n",
    "        while(True):\n",
    "            print(f\"Condition - skip: {skip_users}\")\n",
    "            #TODO: modify this logic when number of users get more than 2000, cuurently skip:200 return only 100 user ids \n",
    "            results_users_positions = query_subgraph(self.query_users_positions.format(f\"skip: {skip_users}\"))\n",
    "            skip_users+=query_user_chunk_num\n",
    "            if results_users_positions['data']:\n",
    "                if results_users_positions['data']['users']:\n",
    "                    data_users_positions_skip = results_users_positions['data']['users']\n",
    "                    print(\"length of data_users_positions_skip-\", len(data_users_positions_skip))\n",
    "                    if len(data_users_positions_skip)==0:\n",
    "                        break\n",
    "                    else:\n",
    "                        data_users_positions.extend(data_users_positions_skip)\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        print(\"total length of data_users_positions -\", len(data_users_positions))\n",
    "        print(\"Running MongoDB operations on user_positions_collection...\")\n",
    "        user_positions_collection.drop()\n",
    "        user_positions_collection.insert_many(data_users_positions)\n",
    "        \n",
    "        return data_users_positions\n",
    "    \n",
    "    def create_notification_data(self, data_users_positions, pdf_pairs_dailyhistory, db_collection):\n",
    "        # def create_user_notifications(data_users_positions, pdf_pairs_dailyhistory):\n",
    "        data_notifications = []\n",
    "        # iterate over the users\n",
    "        for user_pos in data_users_positions:\n",
    "            notif_user_pos = {}\n",
    "            # add user to new dict\n",
    "            notif_user_pos = {'wallet_id': user_pos['id']}\n",
    "\n",
    "            # iterate over the different positions\n",
    "            notif_postions = [] \n",
    "            if user_pos['positions']:\n",
    "                for pos in user_pos['positions']:\n",
    "                    if self.filter_zero_positions(pos):\n",
    "                        notif_pos= {}\n",
    "                        # get the id of each pair\n",
    "                        pos_pair_id = pos['pair']['id']\n",
    "                        # get the information of the partiular pair\n",
    "                        pdf_pair_info = pdf_pairs_dailyhistory[pdf_pairs_dailyhistory['address']==pos_pair_id]\n",
    "                        # extract pair-level features \n",
    "                        pair_asset_decimal = int(pdf_pair_info[\"asset_decimals\"].values[0])\n",
    "                        pair_col_decimal = int(pdf_pair_info[\"collateral_decimals\"].values[0])\n",
    "                        col_unit = pdf_pairs_dailyhistory[\"collateral_symbol\"].values[0]\n",
    "                        pair_symbol = pdf_pairs_dailyhistory[\"show_pair_symbol\"].values[0]\n",
    "                        pair_max_LTV = float(pdf_pair_info[\"maxLTV\"].values[0])/ 10**5\n",
    "                        pair_ex_rate = float(pdf_pair_info[\"dailyHistory_ex_rate_scaled\"].values[0])\n",
    "                        total_col_amt_scaled = int(pdf_pair_info[\"dailyHistory_total_col_amt_scaled\"].values[0])\n",
    "                        pair_borrow_APR = float(pdf_pair_info[\"dailyHistory_borrow_APR\"].values[0])\n",
    "                        pair_lend_APR = float(pdf_pair_info[\"dailyHistory_lend_APR\"].values[0]) \n",
    "                        pos_datetime = datetime_from_timestamp(int(pos['timestamp']))\n",
    "\n",
    "                        # create a new dictionary\n",
    "                        notif_pos = {\n",
    "                            'pos_datetime': pos_datetime,\n",
    "                            'pair_id': pos_pair_id,\n",
    "                            'pair_symbol': pair_symbol,\n",
    "                            'collateral_symbol': col_unit,\n",
    "                            'pair_ex_rate': pair_ex_rate,\n",
    "                            'pair_borrow_APR': pair_borrow_APR,\n",
    "                            'pair_lend_APR': pair_lend_APR,\n",
    "                            }\n",
    "                        \n",
    "                        # calculate features\n",
    "\n",
    "                        # calcualte borrowed amount, shares are not scaled that why take raw features so that the scales cancel out\n",
    "                        try:\n",
    "                            total_b_amt_per_share = int(pdf_pair_info[\"dailyHistory_totalBorrowAmount\"].values[0])/int(pdf_pair_info[\"dailyHistory_totalBorrowShare\"].values[0])\n",
    "                            # borrow_amount =((borrowedAssetShare/10** pair_asset_decimal) * (totalBorrowAmount/totalBorrowShare)) # Unit FRAX\n",
    "                            user_borrow_amt_scaled = round((int(pos[\"borrowedAssetShare\"])/10**pair_asset_decimal) * total_b_amt_per_share, self.round_decimals)\n",
    "                        except (ZeroDivisionError, TypeError):\n",
    "                            user_borrow_amt_scaled = None\n",
    "\n",
    "                        # calculate deposited collateral amount #UNIT col_symbol\n",
    "                        user_dep_col_amt_scaled = round((int(pos[\"depositedCollateralAmount\"])/ 10**pair_col_decimal) , self.round_decimals)\n",
    "\n",
    "                        # calcualte lent amount\n",
    "                        try:\n",
    "                            total_l_amt_per_share = int(pdf_pair_info[\"dailyHistory_totalAssetAmount\"].values[0]) / int(pdf_pair_info[\"dailyHistory_totalAssetShare\"].values[0])\n",
    "                            # lent_amount =((borrowedAssetShare/10** pair_asset_decimal) * (totalAssetAmount/totalAssetShare)) # Unit FRAX\n",
    "                            user_lent_amt_scaled = round((int(pos[\"lentAssetShare\"])/ 10**pair_asset_decimal) * total_l_amt_per_share, self.round_decimals)\n",
    "                        except (ZeroDivisionError, TypeError):\n",
    "                            user_lent_amt_scaled = None\n",
    "                        # calculate current LTV\n",
    "                        # user_borrow_amt_scaled / (user_col_amt_scaled * ex_rate(pair level)) # unit is percentage\n",
    "                        try:\n",
    "                            user_current_LTV = round((user_borrow_amt_scaled/ (total_col_amt_scaled * pair_ex_rate)) *100, 2)\n",
    "                        except (ZeroDivisionError, TypeError):\n",
    "                            user_current_LTV = None\n",
    "                        # calculate Liquidation price \n",
    "                        # LP = user_borrow_amt_scaled / (user_col_amt_scaled * max_LTV) #Unit FRAX\n",
    "                        try:\n",
    "                            user_liquidation_price_scaled = round(user_borrow_amt_scaled / (user_dep_col_amt_scaled * pair_max_LTV), self.round_decimals)\n",
    "                        except (ZeroDivisionError, TypeError):\n",
    "                            user_liquidation_price_scaled = None\n",
    "                        notif_pos[\"user_borrow_amt_scaled\"] = user_borrow_amt_scaled\n",
    "                        notif_pos[\"user_dep_col_amt_scaled\"] = user_dep_col_amt_scaled\n",
    "                        notif_pos[\"user_lent_amt_scaled\"] = user_lent_amt_scaled\n",
    "                        notif_pos[\"user_current_LTV\"] = user_current_LTV\n",
    "                        notif_pos[\"user_liquidation_price_scaled\"] = user_liquidation_price_scaled\n",
    "                        notif_postions.append(notif_pos)\n",
    "                        \n",
    "            notif_user_pos['positions'] = notif_postions\n",
    "            data_notifications.append(notif_user_pos)\n",
    "        # TODO: modify data update logic for each user-positions\n",
    "        print(\"Running MongoDB operations on user_notifications_collection...\")\n",
    "        db_collection.drop()  \n",
    "        db_collection.insert_many(data_notifications)\n",
    "            \n",
    "        return data_notifications\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Data Ingestion \n",
      "...\n",
      "Initializing configurations...\n",
      "Connecting to MongoDB Client...\n",
      "Getting data collections...\n",
      "[Step-1]: getting and ingesting daily history...\n",
      "\n",
      "Staring getting pairs data...\n",
      "Querying Subgraph...\n",
      "De-listing daily history value...\n",
      "Iterating over pairs...\n",
      "Creatinig pandas dataframe...\n",
      "Running MongoDB operations on pairs_collections...\n",
      "[Step-2]: getting and ingesting user positions...\n",
      "\n",
      "Querying Subgraph...\n",
      "initial length of data_users_positions - 1000\n",
      "Condition - skip: 1000\n",
      "Querying Subgraph...\n",
      "length of data_users_positions_skip- 51\n",
      "Condition - skip: 2000\n",
      "Querying Subgraph...\n",
      "total length of data_users_positions - 1051\n",
      "Running MongoDB operations on user_positions_collection...\n",
      "[Step-3]: Creating and ingesting user notifications...\n",
      "\n",
      "Running MongoDB operations on user_notifications_collection...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        print(\"Initializing Data Ingestion \\n...\")\n",
    "        \n",
    "        # manually run \n",
    "        data_ingest = DataIngestion()\n",
    "        # # schedule\n",
    "        # # schedule.every(10).seconds.do(send_notification)\n",
    "        # # segregate_data(query)\n",
    "        # s = schedule.every().day.at(\"13:50\", \"America/New_York\").do(DataIngestion)\n",
    "        # print(\"\\n\",s.next_run)\n",
    "        # # Start an infinite loop to run the scheduler\n",
    "        # while True:\n",
    "        #     schedule.run_pending()\n",
    "        #     time.sleep(1000)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"An exception occurred:\", type(error).__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_fraxbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
